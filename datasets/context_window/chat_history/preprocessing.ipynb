{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import polars as pl\n",
    "from pandas.core.interchange.dataframe_protocol import DataFrame\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "df = pl.read_parquet('hf://datasets/lmsys/lmsys-chat-1m/data/train-*.parquet')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T12:43:12.710109Z",
     "start_time": "2025-04-08T12:43:11.462723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df2 = df.filter(df[\"language\"] == \"English\")\n",
    "df3 = (df2\n",
    "       .filter(df2[\"conversation\"].list.len() == 22)\n",
    "       .filter(pl.col(\"conversation\").is_not_null()).filter(pl.col(\"conversation\").list.eval(\n",
    "    # For each element, check if it has valid struct fields\n",
    "    pl.element().struct.field(\"content\").is_not_null() &\n",
    "    pl.element().struct.field(\"role\").is_not_null() &\n",
    "    # Ensure the fields are strings\n",
    "    pl.element().struct.field(\"content\").cast(pl.String).is_not_null() &\n",
    "    pl.element().struct.field(\"role\").cast(pl.String).is_not_null()\n",
    ").list.all())\n",
    "       .limit(100))"
   ],
   "id": "95c476ab0e0a5444",
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T12:43:18.960729Z",
     "start_time": "2025-04-08T12:43:18.955764Z"
    }
   },
   "cell_type": "code",
   "source": "df4 = pl.DataFrame(df3[\"conversation\"])",
   "id": "3981f8479be10b96",
   "outputs": [],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T13:16:00.185492Z",
     "start_time": "2025-04-08T13:16:00.040341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "df5 = df4.with_columns(\n",
    "    pl.when(\n",
    "        pl.col(\"conversation\").list.slice(0, pl.col(\"conversation\").list.len() - 7).list.last().struct.field(\n",
    "            \"role\") != \"user\"\n",
    "    ).then(\n",
    "        pl.col(\"conversation\").list.slice(0, pl.col(\"conversation\").list.len() - 7).list.slice(0, pl.col(\n",
    "            \"conversation\").list.len() - 1)\n",
    "    ).otherwise(\n",
    "        pl.col(\"conversation\").list.slice(0, pl.col(\"conversation\").list.len() - 7)\n",
    "    )\n",
    ")\n"
   ],
   "id": "ec63c5bc53ffc5d3",
   "outputs": [],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T13:16:30.852299Z",
     "start_time": "2025-04-08T13:16:30.793075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "# Convert the nested conversation column to JSON strings\n",
    "csv_ready_df = df5.with_columns(\n",
    "    pl.col(\"conversation\").map_elements(\n",
    "        lambda row_list: json.dumps([\n",
    "            {\"content\": item[\"content\"], \"role\": item[\"role\"]}\n",
    "            for item in row_list\n",
    "        ]), return_dtype=pl.String\n",
    "    ).alias(\"conversation\")\n",
    ")  # Drop the original nested column and write to CSV\n",
    "csv_ready_df.drop(\"conversation\").write_csv(\"lmsys.csv\")"
   ],
   "id": "2ea8a1f53939191",
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "837f50e5f2a74551",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
