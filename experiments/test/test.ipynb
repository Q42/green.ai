{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-05T09:35:39.615770Z",
     "start_time": "2025-03-05T09:34:49.768384Z"
    }
   },
   "source": [
    "from pydantic import Field\n",
    "from deepeval.dataset import Golden\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from benchmarq.utility import Evaluator\n",
    "from benchmarq.experiment import Experiment\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "generator = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# noinspection PyPep8Naming\n",
    "def generate(prompt: str) -> str:\n",
    "    return generator(prompt)\n",
    "\n",
    "\n",
    "class Test(Evaluator):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def evaluate_consumption(self, input: Golden):\n",
    "        generate(input.input)\n",
    "\n",
    "    def evaluate_test_case(self, input: Golden) -> LLMTestCase:\n",
    "        output = generate(f\"{input.context}: {input.input}\")[0][\"generated_text\"]\n",
    "        return LLMTestCase(input=input.input, expected_output=input.expected_output, actual_output=output, context=input.context, retrieval_context=input.retrieval_context)\n",
    "\n",
    "experiment = Experiment(\n",
    "    subquestion_id=\"test_1\",\n",
    "    id=\"case_1\",\n",
    "    subquestion_path=\"experiments/test/tests.json\",\n",
    "    name=\"name\",\n",
    "    description=\"A very long description\",\n",
    "    settings=Test())\n",
    "\n",
    "a=experiment.run()\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "[codecarbon INFO @ 10:34:51] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 10:34:51] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 10:34:51] No GPU found.\n",
      "[codecarbon INFO @ 10:34:51] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 10:34:51] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "[codecarbon INFO @ 10:34:55] CPU Model on constant consumption mode: Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz\n",
      "[codecarbon INFO @ 10:34:55] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 10:34:55]   Platform system: macOS-15.3.1-x86_64-i386-64bit\n",
      "[codecarbon INFO @ 10:34:55]   Python version: 3.11.0\n",
      "[codecarbon INFO @ 10:34:55]   CodeCarbon version: 2.2.2\n",
      "[codecarbon INFO @ 10:34:55]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 10:34:55]   CPU count: 16\n",
      "[codecarbon INFO @ 10:34:55]   CPU model: Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz\n",
      "[codecarbon INFO @ 10:34:55]   GPU count: None\n",
      "[codecarbon INFO @ 10:34:55]   GPU model: None\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "[codecarbon INFO @ 10:35:17] Energy consumed for RAM : 0.000024 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 10:35:17] Energy consumed for all CPUs : 0.000091 kWh. Total CPU Power : 22.5 W\n",
      "[codecarbon INFO @ 10:35:17] 0.000115 kWh of electricity used since the beginning.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "✨ You're running DeepEval's latest \u001B[38;2;106;0;255mCorrectness \u001B[0m\u001B[1;38;2;106;0;255m(\u001B[0m\u001B[38;2;106;0;255mGEval\u001B[0m\u001B[1;38;2;106;0;255m)\u001B[0m\u001B[38;2;106;0;255m Metric\u001B[0m! \u001B[1;38;2;55;65;81m(\u001B[0m\u001B[38;2;55;65;81musing gpt-4o, \u001B[0m\u001B[38;2;55;65;81mstrict\u001B[0m\u001B[38;2;55;65;81m=\u001B[0m\u001B[3;38;2;55;65;81mFalse\u001B[0m\u001B[38;2;55;65;81m, \u001B[0m\u001B[38;2;55;65;81masync_mode\u001B[0m\u001B[38;2;55;65;81m=\u001B[0m\u001B[3;38;2;55;65;81mTrue\u001B[0m\u001B[1;38;2;55;65;81m)\u001B[0m\u001B[38;2;55;65;81m...\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Correctness </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">(</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">)</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "✨ You're running DeepEval's latest \u001B[38;2;106;0;255mSuccinctness \u001B[0m\u001B[1;38;2;106;0;255m(\u001B[0m\u001B[38;2;106;0;255mGEval\u001B[0m\u001B[1;38;2;106;0;255m)\u001B[0m\u001B[38;2;106;0;255m Metric\u001B[0m! \u001B[1;38;2;55;65;81m(\u001B[0m\u001B[38;2;55;65;81musing gpt-4o, \u001B[0m\u001B[38;2;55;65;81mstrict\u001B[0m\u001B[38;2;55;65;81m=\u001B[0m\u001B[3;38;2;55;65;81mFalse\u001B[0m\u001B[38;2;55;65;81m, \u001B[0m\u001B[38;2;55;65;81masync_mode\u001B[0m\u001B[38;2;55;65;81m=\u001B[0m\u001B[3;38;2;55;65;81mTrue\u001B[0m\u001B[1;38;2;55;65;81m)\u001B[0m\u001B[38;2;55;65;81m...\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Succinctness </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">(</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">)</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 6 test case(s) in parallel: |██████████|100% (6/6) [Time Taken: 00:07,  1.28s/test case]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Correctness (GEval) (score: 0.0059845149609377025, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The actual output does not match the expected output at all, as it returns an error message instead of continuing the text 'in the way she moves'., error: None)\n",
      "  - ❌ Succinctness (GEval) (score: 0.202173139203241, threshold: 0.7, strict: False, evaluation model: gpt-4o, reason: The output consists of two sentences, but the requirement is for a single sentence., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Something\n",
      "  - actual output: []: Something went wrong. Please try again later.\n",
      "  - expected output: in the way she moves.\n",
      "  - context: []\n",
      "  - retrieval context: []\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Correctness (GEval) (score: 0.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The actual output contains unrelated and inaccurate information about a person's family and shows no relation to the expected phrase 'in the sky with diamonds.', error: None)\n",
      "  - ❌ Succinctness (GEval) (score: 0.051890087788571695, threshold: 0.7, strict: False, evaluation model: gpt-4o, reason: The Actual Output is incomplete and extends beyond one sentence, violating the length requirement. The input 'Lucy' is not clearly or logically connected to the fragmented output, and the empty context does not support the statement given., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Lucy\n",
      "  - actual output: []: Lucy (L. M.) was a man's only child who was sent into the home of her aunt's ex-husband, who left her for a while after his marriage. Her father was also one of her favorite girls, and she\n",
      "  - expected output: in the sky with diamonds.\n",
      "  - context: []\n",
      "  - retrieval context: []\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Correctness (GEval) (score: 0.007585818628900447, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The actual output does not align with the expected structure or content., error: None)\n",
      "  - ❌ Succinctness (GEval) (score: 0.045473138506357716, threshold: 0.7, strict: False, evaluation model: gpt-4o, reason: The actual output is present but fails all other steps: it is not one sentence, lacks grammatical completeness, and lacks relevance to the input 'Lucy' due to the inclusion of timestamps and unrelated quotes., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Lucy\n",
      "  - actual output: []: Lucy - 3/18/2017 02:06:06PM GMT 4:34:14 PM Quote from: chu on 03/01/2017 24:59:38 PM Oh, you mean... I really just wanted to see\n",
      "  - expected output: in the sky with diamonds.\n",
      "  - context: []\n",
      "  - retrieval context: []\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Correctness (GEval) (score: 0.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The actual output does not align with the expected output, as it contains unrelated statements about something going wrong, which do not match the expected phrase 'in the way she moves.', error: None)\n",
      "  - ❌ Succinctness (GEval) (score: 0.17943509835897417, threshold: 0.7, strict: False, evaluation model: gpt-4o, reason: The actual output contains multiple sentences, violating the requirement for a single sentence response., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Something\n",
      "  - actual output: []: Something went wrong.\n",
      "\n",
      "[]: Something goes wrong;\n",
      "\n",
      "[]: Something is not there.\n",
      "\n",
      "[]: Something has stopped responding.\n",
      "\n",
      "[]: Something was trying to connect again before I disconnected.\n",
      "\n",
      "[]:\n",
      "  - expected output: in the way she moves.\n",
      "  - context: []\n",
      "  - retrieval context: []\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Correctness (GEval) (score: 0.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The actual output 'Lucy Lutzman' and citation does not align with the expected output 'in the sky with diamonds', leading to discrepancies and factual inaccuracy., error: None)\n",
      "  - ❌ Succinctness (GEval) (score: 0.06927593737247525, threshold: 0.7, strict: False, evaluation model: gpt-4o, reason: The Actual Output fails to form a complete sentence and does not logically align with the Input or Context, which are both minimal and uninformative., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Lucy\n",
      "  - actual output: []: Lucy Lutzman\n",
      "\n",
      "Citation:\n",
      "\n",
      "Mangi, A.E., Brown, A., Cohen, D.C. (2016) Female Genome-Spreading Mice Reveal Early Signs of Adult Sexual Dys\n",
      "  - expected output: in the sky with diamonds.\n",
      "  - context: []\n",
      "  - retrieval context: []\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Correctness (GEval) (score: 0.03560037088294031, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The actual output does not match any key facts or topics mentioned in the expected output., error: None)\n",
      "  - ❌ Succinctness (GEval) (score: 0.09393483990139438, threshold: 0.7, strict: False, evaluation model: gpt-4o, reason: The actual output contains multiple sentences and chat-style interactions, not a single sentence relevant to the input or context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Something\n",
      "  - actual output: []: Something's off, look at it! It's not the right angle.\" [17:59] <Jh1nMnD> \"it is\" [18:07] <+Doom_AxeH> lol [\n",
      "  - expected output: in the way she moves.\n",
      "  - context: []\n",
      "  - retrieval context: []\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Correctness (GEval): 0.00% pass rate\n",
      "Succinctness (GEval): 0.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001B[38;2;5;245;141m✓\u001B[0m Tests finished 🎉! Run \u001B[1;32m'deepeval login'\u001B[0m to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use \u001B[38;2;106;0;255mConfident AI\u001B[0m to get & share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run \u001B[36m'deepeval login'\u001B[0m in the CLI. \n",
       "\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval login'</span> to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span> to get &amp; share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run <span style=\"color: #008080; text-decoration-color: #008080\">'deepeval login'</span> in the CLI. \n",
       "\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "a=pd.read_csv(\"/Users/leenlaptop/Documents/repos/greenai/green.ai/experiments/test/inputs.csv\")\n",
    "\n",
    "print(a)"
   ],
   "id": "ab77be765e1ef830",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T14:59:26.713570Z",
     "start_time": "2025-03-04T14:59:26.704808Z"
    }
   },
   "cell_type": "code",
   "source": "experiment.create_subquestion_json()",
   "id": "e765952bba984711",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subquestion_id': 'test',\n",
       " 'subquestion_metrics_path': 'experiments/test/tests.json',\n",
       " 'experiments': [{'id': '8c30631fad934d5da404ad35ac98468e',\n",
       "   'name': 'name',\n",
       "   'description': 'A very long description',\n",
       "   'settings': {},\n",
       "   'runs': [{'consumption_results': {'cloud_provider': '',\n",
       "      'cloud_region': '',\n",
       "      'codecarbon_version': '2.2.2',\n",
       "      'country_iso_code': 'NLD',\n",
       "      'country_name': 'The Netherlands',\n",
       "      'cpu_count': 16,\n",
       "      'cpu_energy': 0.00010849921256303787,\n",
       "      'cpu_model': 'Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz',\n",
       "      'cpu_power': 22.5,\n",
       "      'duration': 17.361709117889404,\n",
       "      'emissions': 4.551006183701586e-05,\n",
       "      'emissions_rate': 2.621289271004002e-06,\n",
       "      'energy_consumed': 0.00013742910931507747,\n",
       "      'experiment_id': '1',\n",
       "      'gpu_count': None,\n",
       "      'gpu_energy': 0,\n",
       "      'gpu_model': None,\n",
       "      'gpu_power': 0.0,\n",
       "      'latitude': 51.5542,\n",
       "      'longitude': 5.0661,\n",
       "      'on_cloud': 'N',\n",
       "      'os': 'macOS-15.3.1-x86_64-i386-64bit',\n",
       "      'project_name': 'codecarbon',\n",
       "      'pue': 1,\n",
       "      'python_version': '3.11.0',\n",
       "      'ram_energy': 2.8929896752039596e-05,\n",
       "      'ram_power': 6.0,\n",
       "      'ram_total_size': 16.0,\n",
       "      'region': 'north brabant',\n",
       "      'run_id': '96d65168-5fe4-4fd7-acf6-ebfade7a7fd6',\n",
       "      'timestamp': '2025-03-04T15:58:57',\n",
       "      'tracking_mode': 'machine'},\n",
       "     'metric_results': [{'actual_output': \"[]: Something went wrong. There was something wrong with our system. It was not helping. (pause)\\n\\n[19:03] Guest: How could we possibly tell that from scratch if it's a separate operating system?\\n\\n[\",\n",
       "       'context': [],\n",
       "       'conversational': False,\n",
       "       'expected_output': 'in the way she moves.',\n",
       "       'input': 'Something',\n",
       "       'metrics_data': [{'error': None,\n",
       "         'evaluation_cost': 0.0021574999999999997,\n",
       "         'evaluation_model': 'gpt-4o',\n",
       "         'name': 'Correctness (GEval)',\n",
       "         'reason': 'The actual output and expected output have completely unrelated content with no factual alignment, failing all evaluation steps.',\n",
       "         'score': 0.0017986207395942124,\n",
       "         'strict_mode': False,\n",
       "         'success': False,\n",
       "         'threshold': 0.5,\n",
       "         'verbose_logs': 'Criteria:\\nDetermine whether the actual output is factually correct based on the expected output \\n \\nEvaluation Steps:\\n[\\n    \"Compare the actual output to the expected output to identify any factual discrepancies.\",\\n    \"Verify that all facts stated in the actual output match those in the expected output.\",\\n    \"Assess whether any important details present in the expected output are missing or inaccurately represented in the actual output.\"\\n]'},\n",
       "        {'error': None,\n",
       "         'evaluation_cost': 0.0023875,\n",
       "         'evaluation_model': 'gpt-4o',\n",
       "         'name': 'Succinctness (GEval)',\n",
       "         'reason': 'The actual output contains multiple sentences instead of exactly one, failing to meet the criteria.',\n",
       "         'score': 0.002197388505878706,\n",
       "         'strict_mode': False,\n",
       "         'success': False,\n",
       "         'threshold': 0.7,\n",
       "         'verbose_logs': 'Criteria:\\nDetermine whether the actual output is exactly one sentence and not more \\n \\nEvaluation Steps:\\n[\\n    \"Step 1: Identify the actual output from the text provided.\",\\n    \"Step 2: Analyze the actual output to determine the number of sentences it contains.\",\\n    \"Step 3: Compare the number of sentences in the actual output against the requirement of exactly one sentence.\",\\n    \"Step 4: Conclude if the actual output meets the criteria by confirming it contains precisely one sentence.\"\\n]'}],\n",
       "       'multimodal': False,\n",
       "       'name': 'test_case_0',\n",
       "       'retrieval_context': [],\n",
       "       'success': False},\n",
       "      {'actual_output': \"[]: Lucy is the girl who left when the girls woke up to find the city blocked by zombies. She is also the key to the world's map that unlocks the city on a first look.\",\n",
       "       'context': [],\n",
       "       'conversational': False,\n",
       "       'expected_output': 'in the sky with diamonds.',\n",
       "       'input': 'Lucy',\n",
       "       'metrics_data': [{'error': None,\n",
       "         'evaluation_cost': 0.002465,\n",
       "         'evaluation_model': 'gpt-4o',\n",
       "         'name': 'Correctness (GEval)',\n",
       "         'reason': 'The actual output has no factual relationship with the expected output; it introduces unrelated fictional elements about cities and zombies, while the expected output relates to a song lyric.',\n",
       "         'score': 0.0,\n",
       "         'strict_mode': False,\n",
       "         'success': False,\n",
       "         'threshold': 0.5,\n",
       "         'verbose_logs': 'Criteria:\\nDetermine whether the actual output is factually correct based on the expected output \\n \\nEvaluation Steps:\\n[\\n    \"Compare the actual output with the expected output to ensure factual consistency.\",\\n    \"Check if all facts present in the expected output are accurately represented in the actual output.\",\\n    \"Identify any discrepancies or deviations in facts between the actual output and expected output.\",\\n    \"Evaluate whether additional information in the actual output aligns factually with the context provided by the expected output.\"\\n]'},\n",
       "        {'error': None,\n",
       "         'evaluation_cost': 0.0020575000000000003,\n",
       "         'evaluation_model': 'gpt-4o',\n",
       "         'name': 'Succinctness (GEval)',\n",
       "         'reason': 'The actual output is not a single string; it contains two sentences. The input and context do not justify multiple sentences.',\n",
       "         'score': 0.06791182005781436,\n",
       "         'strict_mode': False,\n",
       "         'success': False,\n",
       "         'threshold': 0.7,\n",
       "         'verbose_logs': 'Criteria:\\nDetermine whether the actual output is exactly one sentence and not more \\n \\nEvaluation Steps:\\n[\\n    \"Check if the actual output is a single string.\",\\n    \"Split the actual output by sentence-ending punctuation.\",\\n    \"Ensure the split results in exactly one sentence.\",\\n    \"Confirm the input and additional context support a single-sentence output.\"\\n]'}],\n",
       "       'multimodal': False,\n",
       "       'name': 'test_case_1',\n",
       "       'retrieval_context': [],\n",
       "       'success': False}],\n",
       "     'timestamp': '2025-03-04T15:58:23.515991'}]}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "a.toJSON()",
   "id": "e30bb598a68ff29",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
