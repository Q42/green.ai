{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-04T14:59:14.610486Z",
     "start_time": "2025-03-04T14:58:09.328312Z"
    }
   },
   "source": [
    "from pydantic import Field\n",
    "from deepeval.dataset import Golden\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from benchmarq.utility import Evaluator\n",
    "from benchmarq.experiment import Experiment\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "generator = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# noinspection PyPep8Naming\n",
    "def generate(prompt: str) -> str:\n",
    "    return generator(prompt)\n",
    "\n",
    "\n",
    "class Test(Evaluator):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def evaluate_consumption(self, input: Golden):\n",
    "        generate(input.input)\n",
    "\n",
    "    def evaluate_test_case(self, input: Golden) -> LLMTestCase:\n",
    "        output = generate(f\"{input.context}: {input.input}\")[0][\"generated_text\"]\n",
    "        print(output)\n",
    "        return LLMTestCase(input=input.input, expected_output=input.expected_output, actual_output=output, context=input.context, retrieval_context=input.retrieval_context)\n",
    "\n",
    "experiment = Experiment(\n",
    "    subquestion_id=\"test\",\n",
    "    subquestion_path=\"experiments/test/tests.json\",\n",
    "    name=\"name\",\n",
    "    description=\"A very long description\",\n",
    "    settings=Test())\n",
    "\n",
    "a=experiment.run()\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "[codecarbon INFO @ 15:58:26] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 15:58:26] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 15:58:26] No GPU found.\n",
      "[codecarbon INFO @ 15:58:26] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 15:58:26] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon INFO @ 15:58:27] CPU Model on constant consumption mode: Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz\n",
      "[codecarbon INFO @ 15:58:27] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 15:58:27]   Platform system: macOS-15.3.1-x86_64-i386-64bit\n",
      "[codecarbon INFO @ 15:58:27]   Python version: 3.11.0\n",
      "[codecarbon INFO @ 15:58:27]   CodeCarbon version: 2.2.2\n",
      "[codecarbon INFO @ 15:58:27]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 15:58:27]   CPU count: 16\n",
      "[codecarbon INFO @ 15:58:27]   CPU model: Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz\n",
      "[codecarbon INFO @ 15:58:27]   GPU count: None\n",
      "[codecarbon INFO @ 15:58:27]   GPU model: None\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "[codecarbon INFO @ 15:58:55] Energy consumed for RAM : 0.000025 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:58:55] Energy consumed for all CPUs : 0.000094 kWh. Total CPU Power : 22.5 W\n",
      "[codecarbon INFO @ 15:58:55] 0.000119 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 15:58:57] Energy consumed for RAM : 0.000029 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:58:57] Energy consumed for all CPUs : 0.000108 kWh. Total CPU Power : 22.5 W\n",
      "[codecarbon INFO @ 15:58:57] 0.000137 kWh of electricity used since the beginning.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]: Something went wrong. There was something wrong with our system. It was not helping. (pause)\n",
      "\n",
      "[19:03] Guest: How could we possibly tell that from scratch if it's a separate operating system?\n",
      "\n",
      "[\n",
      "[]: Lucy is the girl who left when the girls woke up to find the city blocked by zombies. She is also the key to the world's map that unlocks the city on a first look.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001B[38;2;106;0;255mCorrectness \u001B[0m\u001B[1;38;2;106;0;255m(\u001B[0m\u001B[38;2;106;0;255mGEval\u001B[0m\u001B[1;38;2;106;0;255m)\u001B[0m\u001B[38;2;106;0;255m Metric\u001B[0m! \u001B[1;38;2;55;65;81m(\u001B[0m\u001B[38;2;55;65;81musing gpt-4o, \u001B[0m\u001B[38;2;55;65;81mstrict\u001B[0m\u001B[38;2;55;65;81m=\u001B[0m\u001B[3;38;2;55;65;81mFalse\u001B[0m\u001B[38;2;55;65;81m, \u001B[0m\u001B[38;2;55;65;81masync_mode\u001B[0m\u001B[38;2;55;65;81m=\u001B[0m\u001B[3;38;2;55;65;81mTrue\u001B[0m\u001B[1;38;2;55;65;81m)\u001B[0m\u001B[38;2;55;65;81m...\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Correctness </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">(</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">)</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001B[38;2;106;0;255mSuccinctness \u001B[0m\u001B[1;38;2;106;0;255m(\u001B[0m\u001B[38;2;106;0;255mGEval\u001B[0m\u001B[1;38;2;106;0;255m)\u001B[0m\u001B[38;2;106;0;255m Metric\u001B[0m! \u001B[1;38;2;55;65;81m(\u001B[0m\u001B[38;2;55;65;81musing gpt-4o, \u001B[0m\u001B[38;2;55;65;81mstrict\u001B[0m\u001B[38;2;55;65;81m=\u001B[0m\u001B[3;38;2;55;65;81mFalse\u001B[0m\u001B[38;2;55;65;81m, \u001B[0m\u001B[38;2;55;65;81masync_mode\u001B[0m\u001B[38;2;55;65;81m=\u001B[0m\u001B[3;38;2;55;65;81mTrue\u001B[0m\u001B[1;38;2;55;65;81m)\u001B[0m\u001B[38;2;55;65;81m...\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Succinctness </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">(</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">)</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating 2 test case(s) in parallel: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|100% (2/2) [Time Taken: 00:10,  5.15s/test case]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚ùå Correctness (GEval) (score: 0.0017986207395942124, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The actual output and expected output have completely unrelated content with no factual alignment, failing all evaluation steps., error: None)\n",
      "  - ‚ùå Succinctness (GEval) (score: 0.002197388505878706, threshold: 0.7, strict: False, evaluation model: gpt-4o, reason: The actual output contains multiple sentences instead of exactly one, failing to meet the criteria., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Something\n",
      "  - actual output: []: Something went wrong. There was something wrong with our system. It was not helping. (pause)\n",
      "\n",
      "[19:03] Guest: How could we possibly tell that from scratch if it's a separate operating system?\n",
      "\n",
      "[\n",
      "  - expected output: in the way she moves.\n",
      "  - context: []\n",
      "  - retrieval context: []\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚ùå Correctness (GEval) (score: 0.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The actual output has no factual relationship with the expected output; it introduces unrelated fictional elements about cities and zombies, while the expected output relates to a song lyric., error: None)\n",
      "  - ‚ùå Succinctness (GEval) (score: 0.06791182005781436, threshold: 0.7, strict: False, evaluation model: gpt-4o, reason: The actual output is not a single string; it contains two sentences. The input and context do not justify multiple sentences., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Lucy\n",
      "  - actual output: []: Lucy is the girl who left when the girls woke up to find the city blocked by zombies. She is also the key to the world's map that unlocks the city on a first look.\n",
      "  - expected output: in the sky with diamonds.\n",
      "  - context: []\n",
      "  - retrieval context: []\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Correctness (GEval): 0.00% pass rate\n",
      "Succinctness (GEval): 0.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001B[38;2;5;245;141m‚úì\u001B[0m Tests finished üéâ! Run \u001B[1;32m'deepeval login'\u001B[0m to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "‚ú®üëÄ Looking for a place for your LLM test data to live üè°‚ù§Ô∏è ? Use \u001B[38;2;106;0;255mConfident AI\u001B[0m to get & share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run \u001B[36m'deepeval login'\u001B[0m in the CLI. \n",
       "\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Tests finished üéâ! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval login'</span> to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "‚ú®üëÄ Looking for a place for your LLM test data to live üè°‚ù§Ô∏è ? Use <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span> to get &amp; share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run <span style=\"color: #008080; text-decoration-color: #008080\">'deepeval login'</span> in the CLI. \n",
       "\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "a=pd.read_csv(\"/Users/leenlaptop/Documents/repos/greenai/green.ai/experiments/test/inputs.csv\")\n",
    "\n",
    "print(a)"
   ],
   "id": "ab77be765e1ef830",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T14:59:26.713570Z",
     "start_time": "2025-03-04T14:59:26.704808Z"
    }
   },
   "cell_type": "code",
   "source": "experiment.create_subquestion_json()",
   "id": "e765952bba984711",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subquestion_id': 'test',\n",
       " 'subquestion_metrics_path': 'experiments/test/tests.json',\n",
       " 'experiments': [{'id': '8c30631fad934d5da404ad35ac98468e',\n",
       "   'name': 'name',\n",
       "   'description': 'A very long description',\n",
       "   'settings': {},\n",
       "   'runs': [{'consumption_results': {'cloud_provider': '',\n",
       "      'cloud_region': '',\n",
       "      'codecarbon_version': '2.2.2',\n",
       "      'country_iso_code': 'NLD',\n",
       "      'country_name': 'The Netherlands',\n",
       "      'cpu_count': 16,\n",
       "      'cpu_energy': 0.00010849921256303787,\n",
       "      'cpu_model': 'Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz',\n",
       "      'cpu_power': 22.5,\n",
       "      'duration': 17.361709117889404,\n",
       "      'emissions': 4.551006183701586e-05,\n",
       "      'emissions_rate': 2.621289271004002e-06,\n",
       "      'energy_consumed': 0.00013742910931507747,\n",
       "      'experiment_id': '1',\n",
       "      'gpu_count': None,\n",
       "      'gpu_energy': 0,\n",
       "      'gpu_model': None,\n",
       "      'gpu_power': 0.0,\n",
       "      'latitude': 51.5542,\n",
       "      'longitude': 5.0661,\n",
       "      'on_cloud': 'N',\n",
       "      'os': 'macOS-15.3.1-x86_64-i386-64bit',\n",
       "      'project_name': 'codecarbon',\n",
       "      'pue': 1,\n",
       "      'python_version': '3.11.0',\n",
       "      'ram_energy': 2.8929896752039596e-05,\n",
       "      'ram_power': 6.0,\n",
       "      'ram_total_size': 16.0,\n",
       "      'region': 'north brabant',\n",
       "      'run_id': '96d65168-5fe4-4fd7-acf6-ebfade7a7fd6',\n",
       "      'timestamp': '2025-03-04T15:58:57',\n",
       "      'tracking_mode': 'machine'},\n",
       "     'metric_results': [{'actual_output': \"[]: Something went wrong. There was something wrong with our system. It was not helping. (pause)\\n\\n[19:03] Guest: How could we possibly tell that from scratch if it's a separate operating system?\\n\\n[\",\n",
       "       'context': [],\n",
       "       'conversational': False,\n",
       "       'expected_output': 'in the way she moves.',\n",
       "       'input': 'Something',\n",
       "       'metrics_data': [{'error': None,\n",
       "         'evaluation_cost': 0.0021574999999999997,\n",
       "         'evaluation_model': 'gpt-4o',\n",
       "         'name': 'Correctness (GEval)',\n",
       "         'reason': 'The actual output and expected output have completely unrelated content with no factual alignment, failing all evaluation steps.',\n",
       "         'score': 0.0017986207395942124,\n",
       "         'strict_mode': False,\n",
       "         'success': False,\n",
       "         'threshold': 0.5,\n",
       "         'verbose_logs': 'Criteria:\\nDetermine whether the actual output is factually correct based on the expected output \\n \\nEvaluation Steps:\\n[\\n    \"Compare the actual output to the expected output to identify any factual discrepancies.\",\\n    \"Verify that all facts stated in the actual output match those in the expected output.\",\\n    \"Assess whether any important details present in the expected output are missing or inaccurately represented in the actual output.\"\\n]'},\n",
       "        {'error': None,\n",
       "         'evaluation_cost': 0.0023875,\n",
       "         'evaluation_model': 'gpt-4o',\n",
       "         'name': 'Succinctness (GEval)',\n",
       "         'reason': 'The actual output contains multiple sentences instead of exactly one, failing to meet the criteria.',\n",
       "         'score': 0.002197388505878706,\n",
       "         'strict_mode': False,\n",
       "         'success': False,\n",
       "         'threshold': 0.7,\n",
       "         'verbose_logs': 'Criteria:\\nDetermine whether the actual output is exactly one sentence and not more \\n \\nEvaluation Steps:\\n[\\n    \"Step 1: Identify the actual output from the text provided.\",\\n    \"Step 2: Analyze the actual output to determine the number of sentences it contains.\",\\n    \"Step 3: Compare the number of sentences in the actual output against the requirement of exactly one sentence.\",\\n    \"Step 4: Conclude if the actual output meets the criteria by confirming it contains precisely one sentence.\"\\n]'}],\n",
       "       'multimodal': False,\n",
       "       'name': 'test_case_0',\n",
       "       'retrieval_context': [],\n",
       "       'success': False},\n",
       "      {'actual_output': \"[]: Lucy is the girl who left when the girls woke up to find the city blocked by zombies. She is also the key to the world's map that unlocks the city on a first look.\",\n",
       "       'context': [],\n",
       "       'conversational': False,\n",
       "       'expected_output': 'in the sky with diamonds.',\n",
       "       'input': 'Lucy',\n",
       "       'metrics_data': [{'error': None,\n",
       "         'evaluation_cost': 0.002465,\n",
       "         'evaluation_model': 'gpt-4o',\n",
       "         'name': 'Correctness (GEval)',\n",
       "         'reason': 'The actual output has no factual relationship with the expected output; it introduces unrelated fictional elements about cities and zombies, while the expected output relates to a song lyric.',\n",
       "         'score': 0.0,\n",
       "         'strict_mode': False,\n",
       "         'success': False,\n",
       "         'threshold': 0.5,\n",
       "         'verbose_logs': 'Criteria:\\nDetermine whether the actual output is factually correct based on the expected output \\n \\nEvaluation Steps:\\n[\\n    \"Compare the actual output with the expected output to ensure factual consistency.\",\\n    \"Check if all facts present in the expected output are accurately represented in the actual output.\",\\n    \"Identify any discrepancies or deviations in facts between the actual output and expected output.\",\\n    \"Evaluate whether additional information in the actual output aligns factually with the context provided by the expected output.\"\\n]'},\n",
       "        {'error': None,\n",
       "         'evaluation_cost': 0.0020575000000000003,\n",
       "         'evaluation_model': 'gpt-4o',\n",
       "         'name': 'Succinctness (GEval)',\n",
       "         'reason': 'The actual output is not a single string; it contains two sentences. The input and context do not justify multiple sentences.',\n",
       "         'score': 0.06791182005781436,\n",
       "         'strict_mode': False,\n",
       "         'success': False,\n",
       "         'threshold': 0.7,\n",
       "         'verbose_logs': 'Criteria:\\nDetermine whether the actual output is exactly one sentence and not more \\n \\nEvaluation Steps:\\n[\\n    \"Check if the actual output is a single string.\",\\n    \"Split the actual output by sentence-ending punctuation.\",\\n    \"Ensure the split results in exactly one sentence.\",\\n    \"Confirm the input and additional context support a single-sentence output.\"\\n]'}],\n",
       "       'multimodal': False,\n",
       "       'name': 'test_case_1',\n",
       "       'retrieval_context': [],\n",
       "       'success': False}],\n",
       "     'timestamp': '2025-03-04T15:58:23.515991'}]}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "a.toJSON()",
   "id": "e30bb598a68ff29",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
